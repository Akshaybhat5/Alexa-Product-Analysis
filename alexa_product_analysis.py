# -*- coding: utf-8 -*-
"""Alexa_product_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qAlFS-4DbAAMhXVJ2pJULk7jO0mUqVXc

**Alexa Product Customer Feedback Analysis**
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import numpy as np

import re
import os
import nltk
import string
nltk.download('stopwords')
from nltk.corpus import stopwords
from wordcloud import WordCloud

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, plot_confusion_matrix, plot_roc_curve
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB, GaussianNB

data = pd.read_csv('amazon_alexa.tsv', delimiter='\t')

data.head()

data.isnull().sum()

data.drop('date', axis = 1, inplace=True)

data.head()

data['length'] = data['verified_reviews'].apply(len)

data.head()

data.info()

data.describe()

data.length.describe()

# max length of the review
data[data['length']==2851]['verified_reviews'].iloc[0]

# Mean length of the review
data[data['length']==132]['verified_reviews'].iloc[0]

# Min length of the review
data[data['length']==1]['verified_reviews'].iloc[0]

"""# ***1.Data Visualization***





"""

data.head()

# rating and variation
plt.figure(figsize=(20,8))
g = sns.barplot(x = 'variation', y = 'rating', data = data, palette='deep')
plt.title('Variation and Rating', weight='bold',fontsize = 18)
plt.xticks(rotation=45,fontsize = 12)
plt.grid(linestyle='--', axis='y')

for i in ['top','left','right']:
    g.spines[i].set_visible(False)
plt.tight_layout()

# rating and variation
plt.figure(figsize=(20,8))
g = sns.barplot(x = 'variation', y = 'rating', data = data, palette='deep', hue = 'feedback')
plt.title('Variation and Rating', weight='bold', fontsize = 18)
plt.xticks(rotation=45,fontsize = 12)
plt.grid(linestyle='--', axis='y')

for i in ['top','left','right']:
    g.spines[i].set_visible(False)
plt.tight_layout()

"""

1. Heather Gray Fabric shows the highest negative feedback product amongst the others.  
2. Following Heather Gray Fabric, Charcoal Fabric and Sandstone Fabric shows the similar negativity product reviews.
3.   Oak Finish and Walnut Finish shows No negative feedback from the users. Either the negative feedback is missing or else it's been not recorded.




"""

# variation and feedback
px.histogram(data_frame=data, x = 'variation', y = np.arange(len(data)), color='feedback', title='Variation and Feedback')

"""1. Black Dot product shows the highest satisfied review from the users.

2. Charcoal Finish follows the Black Dot Design product in a satisfied review.
"""

# length and variation

px.histogram(data_frame=data, x = 'variation', y = 'length', color='feedback', title='Variation and Length')

"""

*   It's been clear from the above graph, the negative review length is very feable compared to the length of positive reviews.

*   People showed lot's of love towards Black Dot finish Alexa Product while explaning their satisfied feedback.




"""

positive = data[data['feedback']==1]
negative = data[data['feedback']==0]

positive

negative

positive_list = positive['verified_reviews'].tolist()
positive_list

def cloud_word(positive_list,title):
    plt.figure(figsize=(12,12))
    plt.imshow(WordCloud().generate(positive_list))
    plt.title(title, weight='bold',fontsize=16)
    plt.tight_layout()

negative_list = negative['verified_reviews'].tolist()

negative_list

positive_list = ' '.join(positive_list)

negative_list = ' '.join(negative_list)

cloud_word(positive_list,'Positive WordCloud')

cloud_word(negative_list, 'Negative WordCloud')

"""# ***2.Data Cleaning***"""

data.head()

# drop rating, length cloumns
data.drop(['rating','length'], axis=1, inplace=True)

data.head()

data.isnull().sum()

data.shape

# let's remove the punctiation, stop words
def text_cleaning(text):
    view = [char for char in text if char not in string.punctuation]
    view = ''.join(view)
    view = [word for word in view.split() if word.lower() not in stopwords.words('english')]
    return view

# let's convert all the text into bunch of numbers
cv = CountVectorizer(analyzer=text_cleaning)
data_with_vectorizer = cv.fit_transform(data['verified_reviews']).toarray()
data_with_vectorizer

data_with_vectorizer = pd.DataFrame(data_with_vectorizer)

data_with_vectorizer

data.head()

data.drop('verified_reviews',axis=1, inplace=True)

data.head()

"""# ***3.Data Preprocessing***"""

data_with_dummies = pd.get_dummies(data['variation'], drop_first=True)
data_with_dummies

data = pd.concat([data_with_dummies, data],axis=1)
data.head()

data.drop('variation',axis=1, inplace=True)

data.head()

data = pd.concat([data_with_vectorizer, data],axis=1)
data.head()

data.info()

"""# ***4.Data Splitting***"""

# split the data into x and y
X = data.iloc[:,:-1].values
y = data.iloc[:,-1].values

X

y

X.shape

y.shape

# split the data into training and testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 365)

X_train.shape

X_test.shape

y_train.shape

y_test.shape

"""# ***5.Model Building***"""

def Model(model, title):
    model.fit(X_train, y_train)
    model_test_score = model.score(X_test, y_test)
    model_train_score = model.score(X_train, y_train)
    y_pred = model.predict(X_test)
    print(f'{title} Test score = {round(model_test_score,4)*100}%')
    cm = confusion_matrix(y_pred, y_test)
    print(classification_report(y_pred, y_test))
    plot_confusion_matrix(model, X_test, y_test)
    plot_roc_curve(model, X_test, y_test)
    plt.tight_layout()

LR = LogisticRegression()
Model(LR, 'Logistic Regression')

NB = MultinomialNB()
Model(NB, 'Naive Bayes')

from sklearn.ensemble import RandomForestClassifier

RF = RandomForestClassifier()
Model(RF,'Random Forest Classifier')

import joblib

joblib.dump(LR, 'Alexa_Customer_Satisfaction_predictor_model.joblib')

